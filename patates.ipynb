{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f93f7bb5-6710-4cf1-938c-982634622d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 363 images belonging to 7 classes.\n",
      "Found 88 images belonging to 7 classes.\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 2.6392 - accuracy: 0.3505 - val_loss: 1.9319 - val_accuracy: 0.2188\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 2s 203ms/step - loss: 2.4679 - accuracy: 0.3565 - val_loss: 2.7940 - val_accuracy: 0.1875\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 3s 229ms/step - loss: 2.0016 - accuracy: 0.3988 - val_loss: 3.4743 - val_accuracy: 0.1875\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 3s 223ms/step - loss: 1.6003 - accuracy: 0.4471 - val_loss: 2.5851 - val_accuracy: 0.1875\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 2s 207ms/step - loss: 1.7633 - accuracy: 0.3867 - val_loss: 2.9286 - val_accuracy: 0.2031\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 1.6239 - accuracy: 0.4290 - val_loss: 2.8892 - val_accuracy: 0.2344\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 1.3641 - accuracy: 0.4972 - val_loss: 2.4434 - val_accuracy: 0.2812\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 3s 220ms/step - loss: 1.2709 - accuracy: 0.5287 - val_loss: 2.5760 - val_accuracy: 0.2500\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 3s 231ms/step - loss: 1.2425 - accuracy: 0.5317 - val_loss: 2.5033 - val_accuracy: 0.3281\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 3s 230ms/step - loss: 1.3778 - accuracy: 0.5015 - val_loss: 2.7868 - val_accuracy: 0.2500\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 3s 226ms/step - loss: 1.3580 - accuracy: 0.4894 - val_loss: 2.9516 - val_accuracy: 0.2656\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 2s 214ms/step - loss: 1.3666 - accuracy: 0.4955 - val_loss: 2.2950 - val_accuracy: 0.3281\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 2s 206ms/step - loss: 1.2890 - accuracy: 0.5287 - val_loss: 2.7166 - val_accuracy: 0.2656\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 2s 211ms/step - loss: 1.2192 - accuracy: 0.5559 - val_loss: 2.4040 - val_accuracy: 0.3594\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 1.3613 - accuracy: 0.4924 - val_loss: 2.2898 - val_accuracy: 0.2969\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 3s 221ms/step - loss: 1.2362 - accuracy: 0.5619 - val_loss: 3.6441 - val_accuracy: 0.1719\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 3s 243ms/step - loss: 1.2604 - accuracy: 0.5257 - val_loss: 2.5160 - val_accuracy: 0.2812\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 3s 224ms/step - loss: 1.0844 - accuracy: 0.5982 - val_loss: 3.3572 - val_accuracy: 0.2812\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 3s 230ms/step - loss: 1.2663 - accuracy: 0.5619 - val_loss: 2.6426 - val_accuracy: 0.2969\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 1.2822 - accuracy: 0.5511 - val_loss: 2.8233 - val_accuracy: 0.3594\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 2s 212ms/step - loss: 1.0736 - accuracy: 0.6224 - val_loss: 3.0405 - val_accuracy: 0.2188\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 3s 228ms/step - loss: 1.0938 - accuracy: 0.5831 - val_loss: 2.4286 - val_accuracy: 0.3125\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 2s 199ms/step - loss: 0.9166 - accuracy: 0.6647 - val_loss: 2.2965 - val_accuracy: 0.2344\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 2s 221ms/step - loss: 1.0664 - accuracy: 0.6314 - val_loss: 2.3540 - val_accuracy: 0.3906\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 1.0158 - accuracy: 0.6449 - val_loss: 3.0083 - val_accuracy: 0.2969\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Veri seti yolu\n",
    "dataset_dir = '/home/onuryilmazo/Desktop/patates/data'\n",
    "\n",
    "# Veri ön işleme ve artırma\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8,1.2],\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2)  # Doğrulama seti için %20 ayrılıyor\n",
    "\n",
    "# Eğitim ve doğrulama veri generator'larını oluşturma\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training')  # Eğitim için veri seti\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')  # Doğrulama için veri seti\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    BatchNormalization(),  # Yeni: Batch normalization\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    BatchNormalization(),  # Yeni: Batch normalization\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    BatchNormalization(),  # Yeni: Batch normalization\n",
    "    Conv2D(128, (3, 3), activation='relu'),  # Yeni: Ekstra bir katman\n",
    "    MaxPooling2D(2, 2),\n",
    "    BatchNormalization(),  # Yeni: Batch normalization\n",
    "    Flatten(),\n",
    "    Dropout(0.5),  # Düzenlileştirme için Dropout\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),  # Yeni: Batch normalization\n",
    "    Dense(7, activation='softmax')  # 7 sınıf için çıkış katmanı\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Modeli eğitin\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56585e8b-45a5-4082-acec-7affa06b24ef",
   "metadata": {},
   "source": [
    "Epoch 25/25\n",
    "11/11 [==============================] - 2s 216ms/step - loss: 1.3329 - accuracy: 0.4985 - val_loss: 1.5016 - val_accuracy: 0.3750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06277e39-eef8-459c-87d5-3f309194437a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 363 images belonging to 7 classes.\n",
      "Found 88 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # Veri setinin %20'si doğrulama için ayrılacak\n",
    ")\n",
    "\n",
    "# Eğitim ve doğrulama veri generator'larını oluşturma\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Eğitim için veri seti\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Doğrulama için veri seti\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be4ad1cd-c731-4807-bdd9-a7b4c6efff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),  # Aşırı uyumu azaltmak için dropout katmanı\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fc5490f-86c5-4c06-82f9-539a222dbb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 4s 247ms/step - loss: 2.1166 - accuracy: 0.1239 - val_loss: 1.9178 - val_accuracy: 0.2969\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onuryilmazo/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 259ms/step - loss: 1.8725 - accuracy: 0.2417 - val_loss: 1.7997 - val_accuracy: 0.3281\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 1.7812 - accuracy: 0.2659 - val_loss: 1.6867 - val_accuracy: 0.2812\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 1.6806 - accuracy: 0.3011 - val_loss: 1.6810 - val_accuracy: 0.3594\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 3s 240ms/step - loss: 1.6285 - accuracy: 0.3202 - val_loss: 1.6772 - val_accuracy: 0.2656\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 1.6414 - accuracy: 0.3293 - val_loss: 1.6291 - val_accuracy: 0.2812\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 1.6097 - accuracy: 0.3414 - val_loss: 1.5846 - val_accuracy: 0.3906\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 1.5570 - accuracy: 0.3595 - val_loss: 1.5431 - val_accuracy: 0.3438\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 2s 219ms/step - loss: 1.5507 - accuracy: 0.3535 - val_loss: 1.5641 - val_accuracy: 0.3594\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 1.5456 - accuracy: 0.3988 - val_loss: 1.4652 - val_accuracy: 0.4375\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 1.4623 - accuracy: 0.4199 - val_loss: 1.4324 - val_accuracy: 0.4375\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 2s 220ms/step - loss: 1.5214 - accuracy: 0.3988 - val_loss: 1.5740 - val_accuracy: 0.3281\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 2s 215ms/step - loss: 1.4753 - accuracy: 0.4199 - val_loss: 1.5972 - val_accuracy: 0.3438\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 1.4234 - accuracy: 0.4502 - val_loss: 1.4163 - val_accuracy: 0.5156\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 3s 222ms/step - loss: 1.4424 - accuracy: 0.4018 - val_loss: 1.4253 - val_accuracy: 0.3906\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 2s 207ms/step - loss: 1.4883 - accuracy: 0.4290 - val_loss: 1.7099 - val_accuracy: 0.2812\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 3s 223ms/step - loss: 1.4713 - accuracy: 0.4169 - val_loss: 1.4382 - val_accuracy: 0.3906\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 2s 211ms/step - loss: 1.3731 - accuracy: 0.4532 - val_loss: 1.4787 - val_accuracy: 0.3594\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 3s 233ms/step - loss: 1.3836 - accuracy: 0.4562 - val_loss: 1.4574 - val_accuracy: 0.3750\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 1.3507 - accuracy: 0.5015 - val_loss: 1.4031 - val_accuracy: 0.3906\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 1.2799 - accuracy: 0.4924 - val_loss: 1.3812 - val_accuracy: 0.4375\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 1.2624 - accuracy: 0.4773 - val_loss: 1.3699 - val_accuracy: 0.4062\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 3s 225ms/step - loss: 1.3104 - accuracy: 0.4545 - val_loss: 1.3700 - val_accuracy: 0.4219\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 2s 208ms/step - loss: 1.2940 - accuracy: 0.4985 - val_loss: 1.5538 - val_accuracy: 0.3594\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 1.3113 - accuracy: 0.4773 - val_loss: 1.3599 - val_accuracy: 0.3906\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 1.3246 - accuracy: 0.4653 - val_loss: 1.2890 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 2s 208ms/step - loss: 1.2931 - accuracy: 0.4834 - val_loss: 1.3462 - val_accuracy: 0.4219\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 1.2812 - accuracy: 0.4864 - val_loss: 1.3634 - val_accuracy: 0.4375\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 3s 227ms/step - loss: 1.2124 - accuracy: 0.4924 - val_loss: 1.4577 - val_accuracy: 0.4219\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 2s 215ms/step - loss: 1.2210 - accuracy: 0.5015 - val_loss: 1.6121 - val_accuracy: 0.4062\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 2s 218ms/step - loss: 1.2570 - accuracy: 0.5196 - val_loss: 1.3659 - val_accuracy: 0.4531\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 2s 216ms/step - loss: 1.2525 - accuracy: 0.5076 - val_loss: 1.5142 - val_accuracy: 0.3594\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 2s 218ms/step - loss: 1.2017 - accuracy: 0.5341 - val_loss: 1.3765 - val_accuracy: 0.5156\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 2s 213ms/step - loss: 1.2180 - accuracy: 0.5166 - val_loss: 1.3585 - val_accuracy: 0.4844\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 1.0895 - accuracy: 0.5680 - val_loss: 1.2699 - val_accuracy: 0.5469\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 3s 225ms/step - loss: 1.1308 - accuracy: 0.5619 - val_loss: 1.2897 - val_accuracy: 0.5156\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 1.1730 - accuracy: 0.5921 - val_loss: 1.1755 - val_accuracy: 0.6250\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 3s 233ms/step - loss: 1.3156 - accuracy: 0.4622 - val_loss: 1.5373 - val_accuracy: 0.4062\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 2s 205ms/step - loss: 1.2192 - accuracy: 0.5378 - val_loss: 1.2403 - val_accuracy: 0.4844\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 2s 202ms/step - loss: 1.3141 - accuracy: 0.4955 - val_loss: 1.4307 - val_accuracy: 0.3906\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 3s 216ms/step - loss: 1.1909 - accuracy: 0.5559 - val_loss: 1.3088 - val_accuracy: 0.4375\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 2s 218ms/step - loss: 1.1558 - accuracy: 0.5287 - val_loss: 1.2042 - val_accuracy: 0.4531\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 2s 216ms/step - loss: 1.0950 - accuracy: 0.5831 - val_loss: 1.3438 - val_accuracy: 0.5312\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 3s 231ms/step - loss: 1.0480 - accuracy: 0.6193 - val_loss: 1.2595 - val_accuracy: 0.5469\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 3s 223ms/step - loss: 1.1108 - accuracy: 0.5801 - val_loss: 1.4187 - val_accuracy: 0.4531\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 2s 214ms/step - loss: 1.0382 - accuracy: 0.5680 - val_loss: 1.2472 - val_accuracy: 0.5469\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 3s 223ms/step - loss: 0.9998 - accuracy: 0.6556 - val_loss: 1.3356 - val_accuracy: 0.4688\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Erken durdurma ve en iyi modeli kaydetmek için callback'ler\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=100,  # Daha fazla epoch, erken durdurma kullanıldığı için sorun olmamalı\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a440b7b5-375e-40dc-9269-875acf753366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 71s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D\n",
    "\n",
    "# Önceden eğitilmiş bir ResNet50 modeli yükleyin\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(150, 150, 3)))\n",
    "\n",
    "# Modelin üst katmanlarını dondurun\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Özel üst katmanlar ekleyin\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(7, activation='softmax')(x)  # 7 sınıf için çıkış katmanı\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6508a136-adc1-4a59-9850-808199751adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 7s 521ms/step - loss: 2.1339 - accuracy: 0.1360 - val_loss: 2.0729 - val_accuracy: 0.1719\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 5s 406ms/step - loss: 2.0169 - accuracy: 0.1782 - val_loss: 2.0202 - val_accuracy: 0.1094\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 5s 423ms/step - loss: 1.9974 - accuracy: 0.1761 - val_loss: 2.0277 - val_accuracy: 0.2344\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 5s 418ms/step - loss: 2.0043 - accuracy: 0.1631 - val_loss: 2.0064 - val_accuracy: 0.1875\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 5s 423ms/step - loss: 1.9640 - accuracy: 0.1571 - val_loss: 1.9822 - val_accuracy: 0.1406\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 5s 408ms/step - loss: 1.9374 - accuracy: 0.2447 - val_loss: 1.8961 - val_accuracy: 0.2500\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 4s 421ms/step - loss: 1.9375 - accuracy: 0.2266 - val_loss: 1.8993 - val_accuracy: 0.2500\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 5s 435ms/step - loss: 1.9118 - accuracy: 0.2145 - val_loss: 1.9161 - val_accuracy: 0.2344\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 5s 414ms/step - loss: 1.9260 - accuracy: 0.2236 - val_loss: 1.9692 - val_accuracy: 0.1875\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 5s 417ms/step - loss: 1.8942 - accuracy: 0.2205 - val_loss: 1.9093 - val_accuracy: 0.1562\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 5s 410ms/step - loss: 1.8941 - accuracy: 0.2085 - val_loss: 1.8618 - val_accuracy: 0.2812\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 5s 423ms/step - loss: 1.8889 - accuracy: 0.2417 - val_loss: 1.8650 - val_accuracy: 0.3438\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 4s 396ms/step - loss: 1.9070 - accuracy: 0.2024 - val_loss: 1.9592 - val_accuracy: 0.1719\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 5s 429ms/step - loss: 1.8907 - accuracy: 0.1994 - val_loss: 1.8268 - val_accuracy: 0.3125\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 4s 396ms/step - loss: 1.8767 - accuracy: 0.2749 - val_loss: 1.8924 - val_accuracy: 0.2188\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 5s 469ms/step - loss: 1.8537 - accuracy: 0.2205 - val_loss: 1.8986 - val_accuracy: 0.2656\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 5s 412ms/step - loss: 1.8409 - accuracy: 0.2508 - val_loss: 1.8841 - val_accuracy: 0.1719\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 5s 429ms/step - loss: 1.8689 - accuracy: 0.2301 - val_loss: 1.9012 - val_accuracy: 0.2344\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 5s 411ms/step - loss: 1.8661 - accuracy: 0.2266 - val_loss: 1.8240 - val_accuracy: 0.2500\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 5s 407ms/step - loss: 1.8435 - accuracy: 0.2447 - val_loss: 1.8834 - val_accuracy: 0.2969\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 5s 421ms/step - loss: 1.8782 - accuracy: 0.2326 - val_loss: 1.9000 - val_accuracy: 0.2031\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 5s 446ms/step - loss: 1.8812 - accuracy: 0.2386 - val_loss: 1.9320 - val_accuracy: 0.2188\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 5s 415ms/step - loss: 1.8695 - accuracy: 0.2870 - val_loss: 1.8914 - val_accuracy: 0.2812\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 5s 404ms/step - loss: 1.8484 - accuracy: 0.2387 - val_loss: 1.8717 - val_accuracy: 0.2656\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 5s 422ms/step - loss: 1.8476 - accuracy: 0.2870 - val_loss: 1.7850 - val_accuracy: 0.3125\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 5s 425ms/step - loss: 1.8555 - accuracy: 0.2779 - val_loss: 1.8598 - val_accuracy: 0.2500\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 5s 413ms/step - loss: 1.8134 - accuracy: 0.2991 - val_loss: 1.7980 - val_accuracy: 0.4062\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 5s 411ms/step - loss: 1.8549 - accuracy: 0.2568 - val_loss: 1.8379 - val_accuracy: 0.2812\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 5s 414ms/step - loss: 1.8238 - accuracy: 0.2598 - val_loss: 1.8640 - val_accuracy: 0.2500\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 5s 437ms/step - loss: 1.8001 - accuracy: 0.2810 - val_loss: 1.8166 - val_accuracy: 0.3125\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 5s 439ms/step - loss: 1.8208 - accuracy: 0.2628 - val_loss: 1.8901 - val_accuracy: 0.2188\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 5s 419ms/step - loss: 1.8322 - accuracy: 0.2689 - val_loss: 1.8571 - val_accuracy: 0.2500\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 5s 434ms/step - loss: 1.8169 - accuracy: 0.2659 - val_loss: 1.8603 - val_accuracy: 0.2656\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 5s 413ms/step - loss: 1.8396 - accuracy: 0.2840 - val_loss: 1.8675 - val_accuracy: 0.2031\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 5s 417ms/step - loss: 1.8701 - accuracy: 0.2387 - val_loss: 1.7976 - val_accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd9fd38a-369e-4512-b658-a561346ef4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 16:17:44.991538: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-16 16:17:45.034642: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-16 16:17:45.697286: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "445c2170-aa2d-48af-8e72-01706357cee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 363 images belonging to 7 classes.\n",
      "Found 88 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Veri setinin yolu\n",
    "dataset_dir = '/home/onuryilmazo/Desktop/patates/data'  # Bu yolu veri setinizin konumuna göre güncelleyin\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca383539-7d7c-4ebb-9489-0b631473b62e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 16:18:59.934106: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-16 16:18:59.938419: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Modelin üst katmanlarını dondurun\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Özel üst katmanları ekleyin\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(7, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d978d0b2-bffa-47c2-9c10-81123e130dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 2.2309 - accuracy: 0.1631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onuryilmazo/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 9s 555ms/step - loss: 2.2309 - accuracy: 0.1631 - val_loss: 2.0787 - val_accuracy: 0.1094\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 5s 445ms/step - loss: 2.0942 - accuracy: 0.1360 - val_loss: 1.9729 - val_accuracy: 0.2031\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 5s 429ms/step - loss: 2.0334 - accuracy: 0.1541 - val_loss: 1.9156 - val_accuracy: 0.1875\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 5s 433ms/step - loss: 1.9998 - accuracy: 0.1631 - val_loss: 1.9092 - val_accuracy: 0.2969\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 5s 448ms/step - loss: 2.0005 - accuracy: 0.1782 - val_loss: 1.9028 - val_accuracy: 0.2656\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 4s 396ms/step - loss: 1.9662 - accuracy: 0.1662 - val_loss: 1.9063 - val_accuracy: 0.2656\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 4s 402ms/step - loss: 1.9530 - accuracy: 0.1813 - val_loss: 1.9122 - val_accuracy: 0.2656\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 5s 437ms/step - loss: 1.9453 - accuracy: 0.1873 - val_loss: 1.8790 - val_accuracy: 0.2656\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 5s 408ms/step - loss: 1.9215 - accuracy: 0.1782 - val_loss: 1.9156 - val_accuracy: 0.2344\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 5s 428ms/step - loss: 1.9555 - accuracy: 0.1692 - val_loss: 1.8997 - val_accuracy: 0.2188\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 4s 396ms/step - loss: 1.9349 - accuracy: 0.2115 - val_loss: 1.8941 - val_accuracy: 0.2344\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 5s 404ms/step - loss: 1.9334 - accuracy: 0.1752 - val_loss: 1.8876 - val_accuracy: 0.2500\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 5s 416ms/step - loss: 1.9209 - accuracy: 0.2236 - val_loss: 1.9033 - val_accuracy: 0.1875\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 5s 438ms/step - loss: 1.9621 - accuracy: 0.1692 - val_loss: 1.8879 - val_accuracy: 0.2031\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 5s 445ms/step - loss: 1.8981 - accuracy: 0.2115 - val_loss: 1.8667 - val_accuracy: 0.2969\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 5s 436ms/step - loss: 1.9066 - accuracy: 0.2236 - val_loss: 1.8622 - val_accuracy: 0.3594\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 5s 409ms/step - loss: 1.9057 - accuracy: 0.2085 - val_loss: 1.8860 - val_accuracy: 0.2031\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 5s 457ms/step - loss: 1.9153 - accuracy: 0.2024 - val_loss: 1.8594 - val_accuracy: 0.2812\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 5s 423ms/step - loss: 1.9104 - accuracy: 0.2024 - val_loss: 1.9169 - val_accuracy: 0.2188\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 5s 434ms/step - loss: 1.9280 - accuracy: 0.2024 - val_loss: 1.8849 - val_accuracy: 0.2656\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 5s 404ms/step - loss: 1.9121 - accuracy: 0.1934 - val_loss: 1.8604 - val_accuracy: 0.2500\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 5s 405ms/step - loss: 1.9220 - accuracy: 0.1722 - val_loss: 1.8696 - val_accuracy: 0.2969\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 5s 446ms/step - loss: 1.9121 - accuracy: 0.2236 - val_loss: 1.8659 - val_accuracy: 0.2812\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 5s 422ms/step - loss: 1.9175 - accuracy: 0.2296 - val_loss: 1.8965 - val_accuracy: 0.2656\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 5s 411ms/step - loss: 1.8896 - accuracy: 0.2085 - val_loss: 1.8734 - val_accuracy: 0.3125\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 5s 410ms/step - loss: 1.9123 - accuracy: 0.2236 - val_loss: 1.8885 - val_accuracy: 0.2188\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 5s 410ms/step - loss: 1.9051 - accuracy: 0.2115 - val_loss: 1.8957 - val_accuracy: 0.2812\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 5s 455ms/step - loss: 1.9048 - accuracy: 0.1903 - val_loss: 1.8953 - val_accuracy: 0.2656\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb381e-a74b-4cdc-be40-4ec87a251e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
